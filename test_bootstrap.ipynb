{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using constrained GP model\n",
    "This is the code used to produce the first example in the paper _'Gaussian processes with linear operator inequality constraints'_, https://arxiv.org/abs/1901.03134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading constrained GP module from C:\\Data\\git repos\\gp_constr\n",
      "Loading R wrapper...\n",
      "Running R from rpy2: R version 3.4.3 (2017-11-30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 3.6.3 (v3.6.3:2c5fed8, Oct  3 2017, 18:11:49) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "### Basic imports ###\n",
    "import sys, os\n",
    "\n",
    "# For plotting\n",
    "import plotly\n",
    "import plotly.plotly as pltly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pltlyoff\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# This is for plotting as static images (to show on e.g. GitHub)\n",
    "import plotly.io as pio\n",
    "from IPython.display import Image\n",
    "\n",
    "# Numerics\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import pyDOE\n",
    "\n",
    "### Custom files ###\n",
    "\n",
    "# Path to custom plotly module 'GPPlotly' for plotting \n",
    "# can be downloaded at https://github.com/cagrell/gp_plotly\n",
    "dir_GPPlotly = 'C:\\\\Data\\\\git repos\\\\gp_plotly\\\\'\n",
    "sys.path.append(dir_GPPlotly) \n",
    "\n",
    "# Path to the constrained GP moule \n",
    "# can be downloaded at https://github.com/cagrell/gp_constr\n",
    "dir_gp_constr = 'C:\\\\Data\\\\git repos\\\\gp_constr\\\\'\n",
    "sys.path.append(dir_gp_constr) \n",
    "\n",
    "# Import\n",
    "from GPPlotly.plottingfunctions import PlotGP2d, add_traces_to_fig\n",
    "from GPConstr.model import kernel_RBF, GPmodel, Constraint\n",
    "\n",
    "### Setup notebook ###\n",
    "pltlyoff.init_notebook_mode(connected=True)\n",
    "print('Python version', sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define function for generating synthetic test/training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to emulate/estimate\n",
    "def fun(x):\n",
    "    return (np.arctan(20*x - 10) - np.arctan(-10))/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regression with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Generate synthetic training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design data - with noise\n",
    "n = 50\n",
    "noise_std = 0.2\n",
    "x_design = np.random.uniform(0.1, 0.8, n)\n",
    "y_design = fun(x_design) + np.random.normal(0, noise_std, n)\n",
    "\n",
    "# For plotting\n",
    "x_test = np.linspace(0, 1, 500)\n",
    "y_true = fun(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Define GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "ker = kernel_RBF(variance = 0.5, lengthscale = [0.1])\n",
    "model = GPmodel(kernel = ker, likelihood = 1, mean = 0) \n",
    "\n",
    "# Add the training data\n",
    "model.X_training = x_design.reshape(-1, 1)\n",
    "model.Y_training = y_design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Include constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for constraints\n",
    "\n",
    "def constant_function(val):\n",
    "    \"\"\" Return the constant function\"\"\"\n",
    "    def fun(x):\n",
    "        return np.array([val]*x.shape[0])\n",
    "    \n",
    "    return fun\n",
    "\n",
    "def fun_UB(x):\n",
    "    \"\"\" Upper bound function \"\"\"\n",
    "    return np.log(30*x.flatten() + 1)/3 + 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints for bounding the function and its derivative\n",
    "constr_bounded = Constraint(LB = constant_function(0), UB = fun_UB)\n",
    "constr_deriv = Constraint(LB = constant_function(0), UB = constant_function(float('Inf')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constraints to model\n",
    "model.constr_bounded = constr_bounded\n",
    "model.constr_deriv = [constr_deriv] # Add list of constraints for multi-dimensional functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- GP model ----- \n",
      " mean = 0 \n",
      " likelihood = 1 \n",
      " kernel: \n",
      "   type = RBF \n",
      "   input dim = 1 \n",
      "   lenghtscale = [0.1] \n",
      "   variance = 0.5 \n",
      " constraint: \n",
      "   f [20], df/dx_1 [6] \n",
      "   constr_likelihood = 1e-06 \n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "# Set virtual points manually \n",
    "model.reset()\n",
    "model.constr_bounded.Xv = pyDOE.lhs(n = 1, samples = 20)\n",
    "model.constr_deriv[0].Xv = pyDOE.lhs(n = 1, samples = 6)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a suitable set of virtual observation locations where the constraint is imposed\n",
    "#df = model.find_XV_subop(bounds = [(0.001, 1)], p_target = 0.9, max_iterations = 100, min_prob_unconstr_xv = -1, i_range = [0, 1], opt_method = 'shgo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a suitable set of virtual observation locations where the constraint is imposed\n",
    "#df = model.find_XV_subop(bounds = [(0.001, 1)], p_target = 0.9, max_iterations = 100, min_prob_unconstr_xv = -1, i_range = [0, 1], opt_method = 'differential_evolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize unconstrained\n",
    "model.optimize(include_constraint = False, fix_likelihood = False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot unconstrained GP\n",
    "mean_unconstr, cov_unconstr = model.calc_posterior_unconstrained(x_test.reshape(-1, 1), full_cov = True)\n",
    "mean_unconstr = np.array(mean_unconstr).flatten()\n",
    "var_unconstr = np.diagonal(cov_unconstr)\n",
    "\n",
    "num_samples = 30\n",
    "show_samplepaths = True\n",
    "samplepaths_unconstr = []\n",
    "if show_samplepaths: samplepaths_unconstr = np.random.multivariate_normal(mean_unconstr, cov_unconstr, num_samples).T\n",
    "\n",
    "fig_unconstr_1 = PlotGP2d(x_mean = x_test, mean = mean_unconstr, var = var_unconstr,\n",
    "                        x_obs = model.X_training[:,0], y_obs = model.Y_training, \n",
    "                        num_std = 1.2815,\n",
    "                        x_true = x_test, y_true = y_true,\n",
    "                        samplepaths = samplepaths_unconstr,\n",
    "                        title = 'Unconstrained GP', xrange = [0, 1], yrange = [-1.7, 1.7], smoothing = True)\n",
    "\n",
    "trace_UB = go.Scatter(x = x_test, y = model.constr_bounded.UB(x_test), mode = 'lines', name = 'Upper bound', line = dict(color = ('rgb(0, 0, 0)'), shape = 'spline', width = 1))\n",
    "trace_LB = go.Scatter(x = x_test, y = model.constr_bounded.LB(x_test), mode = 'lines', name = 'Lower bound', line = dict(color = ('rgb(0, 0, 0)'), shape = 'spline', width = 1))\n",
    "\n",
    "fig_unconstr_1 = add_traces_to_fig(fig_unconstr_1, [trace_UB, trace_LB])\n",
    "\n",
    "pltlyoff.iplot(fig_unconstr_1, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model with both constraints\n",
    "\n",
    "mean, var, perc, mode, samples = model.calc_posterior_constrained(x_test.reshape(-1, 1), compute_mode = False, num_samples = 10000, save_samples = 30, algorithm = 'minimax_tilting', resample = False)\n",
    "\n",
    "mean = np.array(mean).flatten()\n",
    "p_lower = perc[0]\n",
    "median = perc[1]\n",
    "p_upper = perc[2]\n",
    "p_label = '[p{}, p{}]'.format(10, 90)\n",
    "\n",
    "samplepaths_Z = np.array(samples)\n",
    "\n",
    "fig_both = PlotGP2d(x_mean = x_test, mean = mean,\n",
    "                        x_obs = model.X_training[:,0], y_obs = model.Y_training, \n",
    "                        p_lower = p_lower, p_upper = p_upper, p_label = p_label,\n",
    "                        samplepaths =  samplepaths_Z,\n",
    "                        x_true = x_test, y_true = y_true,\n",
    "                        title = 'Both constraints', xrange = [0, 1], yrange = [-1.7, 1.7], smoothing = True)\n",
    "\n",
    "trace_UB = go.Scatter(x = x_test, y = model.constr_bounded.UB(x_test), mode = 'lines', name = 'Upper bound', line = dict(color = ('rgb(0, 0, 0)'), shape = 'spline', width = 1))\n",
    "trace_LB = go.Scatter(x = x_test, y = model.constr_bounded.LB(x_test), mode = 'lines', name = 'Lower bound', line = dict(color = ('rgb(0, 0, 0)'), shape = 'spline', width = 1))\n",
    "trace_XV_bounded = go.Scatter(x = model.constr_bounded.Xv.flatten(), y = np.zeros(model.constr_bounded.Xv.shape[0]), mode = 'markers', name = 'Xv - boundedness', marker = dict(symbol = 'line-ns-open', color = ('rgb(0, 0, 0)')))\n",
    "trace_XV_mon = go.Scatter(x = model.constr_deriv[0].Xv.flatten(), y = np.zeros(model.constr_deriv[0].Xv.shape[0]), mode = 'markers', name = 'Xv - monotonicity', marker = dict(symbol = 'x-thin-open', color = ('rgb(0, 0, 0)')))\n",
    "\n",
    "fig_both = add_traces_to_fig(fig_both, [trace_UB, trace_LB, trace_XV_bounded, trace_XV_mon])\n",
    "#fig_both = add_traces_to_fig(fig_both, [trace_UB, trace_LB, trace_XV_bounded])\n",
    "\n",
    "pltlyoff.iplot(fig_both, filename='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Plot likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "def Create_meshdata(plotfun, x_range, y_range, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Function for creating meshgrid data for surface plotting.\n",
    "    Inputs:\n",
    "        plotfun - function of (x, y, *args, **kwargs)\n",
    "        x_range, y_range\n",
    "    Outputs:\n",
    "        X, Y - meshgrid of x_range and y_range\n",
    "        Z - plotfun(X, Y, *args, **kwargs)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create meshgrid\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    \n",
    "    # Evaluate function\n",
    "    vfun = np.vectorize(plotfun)\n",
    "    Z = [vfun(x, y, *args, **kwargs) for x, y in zip(X, Y)]\n",
    "    \n",
    "    return X, Y, Z\n",
    "\n",
    "def loglik_unconstr(x, y):\n",
    "    \"\"\"\n",
    "    x = kernel lengthscale\n",
    "    y = kernel variance\n",
    "    \"\"\"\n",
    "    model.kernel.variance = y\n",
    "    model.kernel.lengthscale = [x]\n",
    "    model.reset()\n",
    "    return model._loglik_unconstrained()\n",
    "\n",
    "def loglik_constr(x, y):\n",
    "    \"\"\"\n",
    "    x = kernel lengthscale\n",
    "    y = kernel variance\n",
    "    \"\"\"\n",
    "    model.kernel.variance = y\n",
    "    model.kernel.lengthscale = [x]\n",
    "    model.reset()\n",
    "    \n",
    "    v_loglik_unconstr = model._loglik_unconstrained() # P(Y)\n",
    "    v_loglik_constr = np.log(model.constrprob_Xv(posterior = True, algorithm = 'minimax_tilting', n = 100)) # P(C|Y)\n",
    "            \n",
    "    return v_loglik_unconstr + v_loglik_constr # P(Y, C)\n",
    "\n",
    "def loglik_constr_cond(x, y):\n",
    "    \"\"\"\n",
    "    x = kernel lengthscale\n",
    "    y = kernel variance\n",
    "    \"\"\"\n",
    "    model.kernel.variance = y\n",
    "    model.kernel.lengthscale = [x]\n",
    "    model.reset()\n",
    "    \n",
    "    v_loglik_unconstr = model._loglik_unconstrained() # P(Y)\n",
    "    v_loglik_constr_cond = np.log(model.constrprob_Xv(posterior = False, algorithm = 'minimax_tilting', n = 100)) # P(C)\n",
    "    v_loglik_constr = np.log(model.constrprob_Xv(posterior = True, algorithm = 'minimax_tilting', n = 100)) # P(C|Y)\n",
    "                                 \n",
    "    return (v_loglik_constr + v_loglik_constr_cond - v_loglik_unconstr) # P(Y|C)\n",
    "\n",
    "def Q(x, y, g):\n",
    "    \"\"\"\n",
    "    x = kernel lengthscale\n",
    "    y = kernel variance\n",
    "    \"\"\"\n",
    "    model.kernel.variance = y\n",
    "    model.kernel.lengthscale = [x]\n",
    "    model.reset()\n",
    "    \n",
    "    #return model._EM_Q(g)\n",
    "    return model._EM_Q_check(n = 1000) \n",
    "    \n",
    "def compute_Q_meshdata(lengthscale_range, variance_range):\n",
    "    optimal_l = model.kernel.lengthscale[0]\n",
    "    optimal_var = model.kernel.variance\n",
    "    \n",
    "    g = model._EM_g()\n",
    "    \n",
    "    # Create meshgrid\n",
    "    X, Y = np.meshgrid(lengthscale_range, variance_range)\n",
    "    \n",
    "    # Evaluate function\n",
    "    Z = np.zeros(X.shape)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Z[i][j] = Q(X[i][j], Y[i][j], g)\n",
    "    \n",
    "    \n",
    "    # Reset model values\n",
    "    model.kernel.variance = optimal_var\n",
    "    model.kernel.lengthscale = [optimal_l]\n",
    "    model.reset()\n",
    "    \n",
    "    return X, Y, Z\n",
    "    \n",
    "def compute_loglik_meshdata(lengthscale_range, variance_range, constr = False, conditional = False):\n",
    "    optimal_l = model.kernel.lengthscale[0]\n",
    "    optimal_var = model.kernel.variance\n",
    "    \n",
    "    if constr:\n",
    "        if conditional:\n",
    "            X1, X2, Y = Create_meshdata(loglik_constr_cond, lengthscale_range, variance_range)                    \n",
    "        else:\n",
    "            X1, X2, Y = Create_meshdata(loglik_constr, lengthscale_range, variance_range)\n",
    "    else:\n",
    "        X1, X2, Y = Create_meshdata(loglik_unconstr, lengthscale_range, variance_range)\n",
    "    \n",
    "    # Reset model values\n",
    "    model.kernel.variance = optimal_var\n",
    "    model.kernel.lengthscale = [optimal_l]\n",
    "    model.reset()\n",
    "    \n",
    "    return X1, X2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize unconstrained\n",
    "model.likelihood = 1\n",
    "model.reset()\n",
    "model.optimize(include_constraint = False, fix_likelihood = True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unconstrained likelihood\n",
    "lengthscale_range = np.linspace(0.05, 1, 20)\n",
    "variance_range = np.linspace(0.1, 3, 20)\n",
    "\n",
    "X1, X2, Y = compute_loglik_meshdata(lengthscale_range, variance_range, constr = False)\n",
    "\n",
    "contour_unconstr = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Unconstrained log-likelihood',\n",
    "                                autocontour = False, contours=dict(start = -52, end = -50, size = 0.2),\n",
    "                             )\n",
    "max_unconstr = go.Scatter(x = [model.kernel.lengthscale[0]], y = [model.kernel.variance], mode = 'markers', name = 'current')\n",
    "\n",
    "data = [contour_unconstr, max_unconstr]\n",
    "layout = go.Layout(title = 'Unconstrained log-likelihood', xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')\n",
    "print('Optimal: {}, {}'.format(model.kernel.lengthscale[0], model.kernel.variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained - global\n",
    "\n",
    "#opt_args = {'maxiter': 10}\n",
    "opt_args = {}\n",
    "\n",
    "bound_lik = None\n",
    "bound_ker_var = (0.1, 3)\n",
    "bound_ker_len = [(0.1, 2)]*1\n",
    "\n",
    "bounds = [bound_lik] if bound_lik is not None else []\n",
    "bounds = bounds + [bound_ker_var] + bound_ker_len\n",
    "#bounds = None\n",
    "model._optimize_constrained(fix_likelihood = True, conditional = False, opt_method = 'differential_evolution', \n",
    "                            algorithm = 'minimax_tilting', n = 10, opt_args = opt_args, bounds = bounds)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained - local\n",
    "\n",
    "#opt_args = {'maxiter': 10}\n",
    "opt_args = {}\n",
    "\n",
    "bounds = [(1e-6, None)]*2\n",
    "\n",
    "model._optimize_constrained(fix_likelihood = True, conditional = False, opt_method = 'L-BFGS-B', \n",
    "                            algorithm = 'minimax_tilting', n = 10, opt_args = opt_args, bounds = bounds)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.likelihood = 0.1\n",
    "model.reset()\n",
    "model.constrprob_Xv(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained\n",
    "model.constr_likelihood = 1E-6\n",
    "model.kernel.lengthscale = [0.1]\n",
    "model.kernel.variance = 0.5\n",
    "model.reset()\n",
    "\n",
    "opt_args = {'options' : {'maxtime ':10}}\n",
    "opt_args = {}\n",
    "model._optimize_constrained(fix_likelihood = True, opt_method = 'shgo', algorithm = 'minimax_tilting', n = 10, opt_args = opt_args)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute constrained likelihood\n",
    "import time\n",
    "#model.constr_likelihood = 1E-3\n",
    "model.reset()\n",
    "lengthscale_range = np.linspace(0.05, 1, 20)\n",
    "variance_range = np.linspace(0.1, 3, 20)\n",
    "\n",
    "t0 = time.time()\n",
    "X1, X2, Y = compute_loglik_meshdata(lengthscale_range, variance_range, constr = True)\n",
    "print('time ', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_constr = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Constrained log-likelihood',\n",
    "                                autocontour = True, contours=dict(start = -54, end = -50, size = 0.15),\n",
    "                             )\n",
    "max_constr = go.Scatter(x = [model.kernel.lengthscale[0]], y = [model.kernel.variance], mode = 'markers', name = 'current')\n",
    "\n",
    "data = [contour_constr, max_unconstr, max_constr]\n",
    "layout = go.Layout(title = 'Constrained log-likelihood, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')\n",
    "print('Optimal: {}, {}'.format(model.kernel.lengthscale[0], model.kernel.variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Q\n",
    "X1, X2, Y = compute_Q_meshdata(lengthscale_range, variance_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_Q = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Q',\n",
    "                                autocontour = True, contours=dict(start = -54, end = -50, size = 0.15),\n",
    "                             )\n",
    "\n",
    "data = [contour_Q]\n",
    "layout = go.Layout(title = 'Q, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Q\n",
    "X1, X2, Y = compute_Q_meshdata(lengthscale_range, variance_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_Q = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Q',\n",
    "                                autocontour = True, contours=dict(start = -54, end = -50, size = 0.15),\n",
    "                             )\n",
    "\n",
    "data = [contour_Q]\n",
    "layout = go.Layout(title = 'Q, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_constr = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Constrained log-likelihood',\n",
    "                                autocontour = False, contours=dict(start = -54, end = -50, size = 0.15),\n",
    "                             )\n",
    "max_constr = go.Scatter(x = [model.kernel.lengthscale[0]], y = [model.kernel.variance], mode = 'markers', name = 'current')\n",
    "\n",
    "data = [contour_unconstr, max_unconstr, max_constr]\n",
    "layout = go.Layout(title = 'Constrained log-likelihood, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')\n",
    "print('Optimal: {}, {}'.format(model.kernel.lengthscale[0], model.kernel.variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute constrained likelihood\n",
    "import time\n",
    "#model.constr_likelihood = 1E-3\n",
    "model.reset()\n",
    "lengthscale_range = np.linspace(0.05, 5, 30)\n",
    "variance_range = np.linspace(0.1, 1, 30)\n",
    "\n",
    "t0 = time.time()\n",
    "X1, X2, Y = compute_loglik_meshdata(lengthscale_range, variance_range, constr = True, conditional = True)\n",
    "print('time ', time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_constr_cond = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Constrained log-likelihood',\n",
    "                                autocontour = False, contours=dict(start = 45, end = 48, size = 0.5),\n",
    "                             )\n",
    "max_constr_cond = go.Scatter(x = [model.kernel.lengthscale[0]], y = [model.kernel.variance], mode = 'markers', name = 'current')\n",
    "\n",
    "data = [contour_constr_cond, max_unconstr, max_constr, max_constr_cond]\n",
    "layout = go.Layout(title = 'Constrained conditional log-likelihood, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')\n",
    "print('Optimal: {}, {}'.format(model.kernel.lengthscale[0], model.kernel.variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_constr_cond = go.Contour(\n",
    "                                x = lengthscale_range, y = variance_range, z = Y, name = 'Constrained log-likelihood',\n",
    "                                autocontour = False, contours=dict(start = 45, end = 51, size = 0.5),\n",
    "                             )\n",
    "max_constr_cond = go.Scatter(x = [model.kernel.lengthscale[0]], y = [model.kernel.variance], mode = 'markers', name = 'current')\n",
    "\n",
    "data = [contour_constr_cond, max_unconstr, max_constr, max_constr_cond]\n",
    "layout = go.Layout(title = 'Constrained conditional log-likelihood, noise_var = ' + str(model.constr_likelihood), xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'variance'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')\n",
    "print('Optimal: {}, {}'.format(model.kernel.lengthscale[0], model.kernel.variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new alg bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_constr_loglik(model, intermediate = True):\n",
    "    v_loglik_unconstr = model._loglik_unconstrained() # P(Y)\n",
    "    v_loglik_constr = np.log(model.constrprob_Xv(posterior = True, algorithm = 'minimax_tilting', n = 1000)) # P(C|Y)\n",
    "    \n",
    "    if intermediate:\n",
    "        print('P(Y)', v_loglik_unconstr)\n",
    "        print('P(C|Y)', v_loglik_constr)\n",
    "    \n",
    "    print('P(Y, C)', v_loglik_unconstr + v_loglik_constr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.likelihood = 1\n",
    "model.kernel.variance = 0.5\n",
    "model.kernel.lengthscale = [0.1]\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Running optimization for unconstrained GP ... DONE - Total time: 0.088 seconds\n",
      "----- GP model ----- \n",
      " mean = 0 \n",
      " likelihood = 0.03548499979269271 \n",
      " kernel: \n",
      "   type = RBF \n",
      "   input dim = 1 \n",
      "   lenghtscale = [0.29251104] \n",
      "   variance = 0.34576448836813417 \n",
      " constraint: \n",
      "   f [20], df/dx_1 [6] \n",
      "   constr_likelihood = 1e-06 \n",
      "---------------------\n",
      "P(Y) 5.041485472059151\n",
      "P(C|Y) -8.139435123914025\n",
      "P(Y, C) -3.097949651854874\n"
     ]
    }
   ],
   "source": [
    "# Optimize unconstrained\n",
    "model.optimize(include_constraint = False, fix_likelihood = False)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..Running calculation of g(theta~) ... DONE - time: 0.044 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.335 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.047 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.095 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.047 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.139 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.035 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.094 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.047 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.120 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.040 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.492 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.047 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.430 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.031 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.156 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.061 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.104 seconds\n",
      "..Running calculation of g(theta~) ... DONE - time: 0.052 seconds\n",
      "..Running optimization (L-BFGS-B) ... DONE - time: 0.268 seconds\n",
      "----- GP model ----- \n",
      " mean = 0 \n",
      " likelihood = 0.03637051773963954 \n",
      " kernel: \n",
      "   type = RBF \n",
      "   input dim = 1 \n",
      "   lenghtscale = [0.29376378] \n",
      "   variance = 0.3982106210073909 \n",
      " constraint: \n",
      "   f [20], df/dx_1 [6] \n",
      "   constr_likelihood = 1e-06 \n",
      "---------------------\n",
      "P(Y) 5.017810205604228\n",
      "P(C|Y) -8.083892398463142\n",
      "P(Y, C) -3.0660821928589144\n"
     ]
    }
   ],
   "source": [
    "# EM updates\n",
    "#bounds = [(1e-6, 1), (1e-6, 30), (1e-6, 10)]\n",
    "bounds = None\n",
    "\n",
    "#model._EM_update(fix_likelihood = False, bounds = bounds, n = 1000, verbatim = True, opt_method = 'shgo')\n",
    "for i in range(10):\n",
    "    model._EM_update(fix_likelihood = False, bounds = bounds, n = 1000, verbatim = True)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained local\n",
    "opt_args = {}\n",
    "\n",
    "bounds = [(1e-6, None)]*3\n",
    "\n",
    "model._optimize_constrained(fix_likelihood = False, conditional = False, opt_method = 'L-BFGS-B', \n",
    "                            algorithm = 'minimax_tilting', n = 10, opt_args = opt_args, bounds = bounds)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained global\n",
    "opt_args = {}\n",
    "\n",
    "#bounds = [(1e-6, None)]*2\n",
    "bounds = [(1e-1, 1), (1e-6, 30), (1e-6, 10)]\n",
    "\n",
    "model._optimize_constrained(fix_likelihood = False, conditional = False, opt_method = 'differential_evolution', \n",
    "                            algorithm = 'minimax_tilting', n = 10, opt_args = opt_args, bounds = bounds)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Y) -52.149008618996795\n",
      "P(C|Y) -11.03796754738172\n",
      "P(Y, C) -63.186976166378514\n"
     ]
    }
   ],
   "source": [
    "model.kernel.lengthscale = [0.1]\n",
    "model.kernel.variance = 0.5\n",
    "model.likelihood = 1\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize(include_constraint = False, fix_likelihood = True)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounds = [(0.1, None)]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._EM_update(fix_likelihood = False, bounds = None, n = 1000, verbatim = True)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize constrained - local\n",
    "\n",
    "#opt_args = {'maxiter': 10}\n",
    "opt_args = {}\n",
    "\n",
    "bounds = [(1e-6, None)]*2\n",
    "\n",
    "model._optimize_constrained(fix_likelihood = True, conditional = False, opt_method = 'L-BFGS-B', \n",
    "                            algorithm = 'minimax_tilting', n = 10, opt_args = opt_args, bounds = bounds)\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = model._EM_g()\n",
    "Q, zGz = model._EM_Q(g)\n",
    "\n",
    "print(Q)\n",
    "print(zGz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_check, zGz_check = model._EM_Q_check(n = 1000)\n",
    "print(Q_check)\n",
    "print(zGz_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_sim, Gamma, Gamma_inv, L = model._EM_Q_check(n = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.zeros(C_sim.shape[0])\n",
    "tmp_2 = None\n",
    "\n",
    "for i in range(C_sim.shape[0]):\n",
    "    z = np.matrix(list(model.Y_centered.flatten()) + list(C_sim[i])).T\n",
    "    tmp[i] = (z.T*Gamma_inv*z)[0,0]\n",
    "    if tmp_2 is None:\n",
    "        tmp_2 = z*z.T\n",
    "    else:\n",
    "        tmp_2 = tmp_2 + z*z.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_1 = np.array(tmp).mean()\n",
    "print(avg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_z_zt = tmp_2/C_sim.shape[0]\n",
    "avg_2 = np.sum(np.diag(E_z_zt*Gamma_inv))\n",
    "\n",
    "avg_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1D Q\n",
    "\n",
    "def Q_calc(x, g = None):\n",
    "    l = model.kernel.lengthscale[0]\n",
    "    model.kernel.lengthscale[0] = x\n",
    "    model.reset()\n",
    "    \n",
    "    if g is None:\n",
    "        gg = model._EM_g()\n",
    "    else:\n",
    "        gg = g\n",
    "    \n",
    "    Q = model._EM_Q(gg)\n",
    "    \n",
    "    model.kernel.lengthscale[0] = l\n",
    "    model.reset()\n",
    "    \n",
    "    return Q\n",
    "\n",
    "def Q_check_calc(x):\n",
    "    l = model.kernel.lengthscale[0]\n",
    "    model.kernel.lengthscale[0] = x\n",
    "    model.reset()\n",
    "    \n",
    "    Q, zGz, H, det_1, det_2 = model._EM_Q_check(n = 1000)\n",
    "    \n",
    "    model.kernel.lengthscale[0] = l\n",
    "    model.reset()\n",
    "    \n",
    "    return H\n",
    "\n",
    "def loglik_all(x):\n",
    "    l = model.kernel.lengthscale[0]\n",
    "    model.kernel.lengthscale[0] = x\n",
    "    model.reset()\n",
    "    \n",
    "    v_loglik_unconstr = model._loglik_unconstrained() # P(Y)\n",
    "    v_loglik_constr = np.log(model.constrprob_Xv(posterior = True, algorithm = 'minimax_tilting', n = 1000)) # P(C|Y)\n",
    "            \n",
    "    model.kernel.lengthscale[0] = l\n",
    "    model.reset()\n",
    "    \n",
    "    return v_loglik_unconstr, v_loglik_constr, v_loglik_unconstr + v_loglik_constr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize unconstrained\n",
    "model.optimize(include_constraint = False, fix_likelihood = True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q \n",
    "x = np.linspace(0.1, 0.23, 20)\n",
    "g_opt = model._EM_g()\n",
    "Q_opt = np.array([Q_calc(xx, g_opt) for xx in x])\n",
    "Q_current = np.array([Q_calc(xx) for xx in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log P(Y, C)\n",
    "log_P_Y = np.zeros(x.shape[0])\n",
    "log_P_CgY = np.zeros(x.shape[0])\n",
    "log_P_YC = np.zeros(x.shape[0])\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    log_P_Y[i], log_P_CgY[i], log_P_YC[i] = loglik_all(x[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q check\n",
    "Q_check = np.array([Q_check_calc(xx) for xx in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "trace_loglik = go.Scatter(x = x, y = log_P_YC, mode = 'lines', name = 'log P(Y, C)')\n",
    "trace_loglik_2 = go.Scatter(x = x, y = log_P_Y, mode = 'lines', name = 'log P(Y)')\n",
    "\n",
    "trace_Q_opt = go.Scatter(x = x, y = Q_opt, mode = 'lines', name = 'Q_opt')\n",
    "trace_Q_current = go.Scatter(x = x, y = Q_current, mode = 'lines', name = 'Q_current')\n",
    "trace_Q_check = go.Scatter(x = x, y = Q_check, mode = 'lines', name = 'ELBO')\n",
    "\n",
    "data = [trace_loglik, trace_Q_opt, trace_Q_current, trace_Q_check, trace_loglik_2]\n",
    "layout = go.Layout(title = '', xaxis=dict(title = 'lengthscale'), yaxis=dict(title = 'log likelihood'))\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "pltlyoff.iplot(fig, filename='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.kernel.lengthscale = [0.18]\n",
    "model.reset()\n",
    "print(model)\n",
    "print_constr_loglik(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = model._EM_g()\n",
    "Q_opt = model._EM_Q(g_opt)\n",
    "print(Q_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_check, zGz, H, det_1, det_2 = model._EM_Q_check(n = 1000)\n",
    "\n",
    "print(Q_check)\n",
    "print(zGz)\n",
    "print(H)\n",
    "print(det_1)\n",
    "#print(det_2)\n",
    "print(Q_check + H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(-54.26315345870914)-Q_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = model._num_virtuial_pts() + model.Y_training.shape[0]\n",
    "#-det_1 - (n/2)*np.log(2*np.pi) -0.5*zGz\n",
    "- (n/2)*np.log(2*np.pi) -0.5*zGz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2T_K_x_xv = model._calc_L2T(model.X_training)\n",
    "L1L2T_K_xv_xv = model._calc_L1L2()\n",
    "Gamma = np.block([[model.K_w, L2T_K_x_xv], [L2T_K_x_xv.T, L1L2T_K_xv_xv + model.constr_likelihood*np.identity(n = L1L2T_K_xv_xv.shape[0])]])\n",
    "L = np.linalg.cholesky(Gamma)\n",
    "np.log(np.diag(L)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.diag(model.K_w)\n",
    "L2T_K_x_xv = model._calc_L2T(model.X_training)\n",
    "L2T_K_x_xv.shape\n",
    "L1L2T_K_xv_xv = model._calc_L1L2()\n",
    "L1L2T_K_xv_xv.shape\n",
    "\n",
    "np.identity(n = L1L2T_K_xv_xv.shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.linalg.cholesky(model.B1)\n",
    "np.diag(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Q_check)\n",
    "print(model._loglik_unconstrained())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.B1\n",
    "B1_inv = np.linalg.inv(model.B1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.log(np.linalg.det(model.B1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.linalg.cholesky(model.B1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.log(np.diag(L)).sum()\n",
    "\n",
    "2*np.log(np.diag(L)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPConstr.r_functions.python_wrappers import mtmvnorm, moments_from_samples, rtmvnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs = 2\n",
    "rho = 0.5\n",
    "a = 0.5\n",
    "b = 1\n",
    "\n",
    "# Distribution of c|Y\n",
    "cond_mean = rho*y_obs\n",
    "cond_var = 1 - rho**2\n",
    "\n",
    "# P(Y)\n",
    "ln_P_Y = -(1/2)*np.log(2*np.pi) - y_obs**2\n",
    "ln_P_CgY = np.log(sp.stats.norm.cdf(b, loc=cond_mean, scale=cond_var) - sp.stats.norm.cdf(a, loc=cond_mean, scale=cond_var))\n",
    "\n",
    "print('logP(Y)', ln_P_Y)\n",
    "print('logP(C|Y)', ln_P_CgY)\n",
    "print('logP(Y, C)', ln_P_Y + ln_P_CgY)\n",
    "\n",
    "# EM\n",
    "Gamma = np.matrix([[1, rho], [rho, 1]])\n",
    "Gamma_inv = np.linalg.inv(Gamma)\n",
    "\n",
    "# Moments of truncated variable\n",
    "cm, cs = mtmvnorm(np.array([0]), np.matrix([[1]]), [a], [b])\n",
    "#cm, cs = moments_from_samples(1000, np.array([0]), np.matrix([[1]]), [a], [b])\n",
    "cm = cm[0]\n",
    "cs = cs[0][0]\n",
    "\n",
    "# g matrix\n",
    "g = np.matrix([[y_obs**2, y_obs*cm], [y_obs*cm, cs + cm**2]])\n",
    "\n",
    "\n",
    "# Q\n",
    "# Sample from constraint distribution\n",
    "C_sim = rtmvnorm(100, np.array([0]), np.matrix([[1]]), [a], [b]).flatten()\n",
    "\n",
    "Q = -0.5*np.diag(g*Gamma_inv).sum() - 0.5*np.log(np.linalg.det(Gamma)) -(2/2)*np.log(2*np.pi)\n",
    "#H = (1/2)*np.log(2*np.pi) + np.log(sp.stats.norm.cdf(b) - sp.stats.norm.cdf(a)) + (C_sim**2).mean() # Wrong ?\n",
    "\n",
    "Z = np.exp(ln_P_CgY)\n",
    "alpha = (a - cond_mean)/np.sqrt(cond_var)\n",
    "beta = (b - cond_mean)/np.sqrt(cond_var)\n",
    "\n",
    "H = np.log(np.sqrt(2*np.pi*np.exp(1))*np.sqrt(cond_var)*Z) + (alpha*sp.stats.norm.pdf(alpha) - beta*sp.stats.norm.pdf(beta))/(2*Z)\n",
    "\n",
    "print('')\n",
    "print('Q', Q)\n",
    "print('H', H)\n",
    "print('ELBO', Q + H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from constraint distribution\n",
    "C_sim = rtmvnorm(100, np.array([0]), np.matrix([[1]]), [a], [b]).flatten()\n",
    "\n",
    "(C_sim**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.exp(ln_P_CgY)\n",
    "alpha = (a - cond_mean)/np.sqrt(cond_var)\n",
    "beta = (b - cond_mean)/np.sqrt(cond_var)\n",
    "\n",
    "np.log(np.sqrt(2*np.pi*np.exp(1))*np.sqrt(cond_var)*Z) + (alpha*sp.stats.norm.pdf(alpha) - beta*sp.stats.norm.pdf(beta))/(2*Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize unconstrained\n",
    "model.optimize(include_constraint = False, fix_likelihood = True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.norm.cdf(1/2.2, loc=0, scale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
